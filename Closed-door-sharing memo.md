Oppie PRD5 备忘录：构建下一代AI工程师
DATE: 2025年8月11日 
SUBJECT: 关于打造开源版Google Jules (Oppie) 的战略分析与行动方案
说明: 本备忘录记录了来自和前沿R&D人员闭门会议的行业校准。它不仅验证了我们最初的战略方向，更重要的是，它用来自OpenAI、Google、Anthropic等头部公司的最新工程实践，为我们的“护城河”理论注入了现实约束，并为Oppie的下一步演进提供了具体、可执行的“硬动作”。
Part 1: Google Jules这类产品的核心Know-How是什么？
我们的核心判断依然成立，但必须用更严苛的工程现实来重新标定：
1. 核心是“搜索与验证循环”，而非“生成”
这是最关键的认知转变。Jules/Oppie的核心是 目标 -> [探索 -> 实现 -> 测试 -> 评估] -> 学习 -> 优化 -> 交付 的循环。
 * Know-How : 关键在于循环的速度和质量。MCTS的每次模拟都必须在高保真、低延迟、完全隔离的环境中运行。
   * 现实约束: 将一次“测试-验证”循环从分钟级压缩到秒级是当前阶段的现实目标。毫秒/微秒级是远景。
   * 实现路径: 放弃将GitHub Actions作为主循环沙箱。主循环必须迁移到热态、内存级的轻量虚拟化环境（如Firecracker、gVisor或基于Devcontainer的持久化VM池），CI只作为最终面向外部的、可审计的验证关卡。
2. “奖励函数（Reward Function）”是真正的艺术
MCTS的灵魂在于评估一个“节点”的好坏。
 * Know-How: 一个顶级的奖励函数是多维度的，并且必须硬化为可量化的工程指标。
   * 功能性指标：测试通过率、性能基准。
   * 非功能性指标：代码复杂度、可读性、代码变更行数。
   * 成本指标：Token消耗、计算资源（VM-分钟）。
   * 未来可扩展性：耦合度、接口设计清晰度。
   * [新增] 基础设施与风险指标: 这是至关重要的补充。必须包含部署/运行态的SLO（P95延迟、冷启动时间、内存峰值）、网络出站成本、权限范围、依赖树风险评分（CVE）。否则，系统会产生“在理论上漂亮但在现实中昂贵或危险”的解。
   * [新增] 调优方法: 权重设计应避免手动调整，采用成对偏好优化（DPO/Pairwise Preference Optimization），让系统从“A方案优于B方案”的比较中学习权重。
3. 状态管理是性能瓶颈的根源
MCTS会产生海量的中间代码状态。
 * Know-How: 挑战在于近乎零成本的状态切换。Git Worktree是很好的起点，但无法支撑秒级循环。最终解法是内容寻址存储（CAS）与写时复制（COW）快照的结合，运行在专用的VM文件系统之上（如overlayfs）。PRD4中的哈希快照方向完全正确，但其运行的“底座”需要升级。
4. 分层规划与任务分解（Hierarchical Planning）
高级工程师会先分解任务再执行。
 * Know-How: Jules的“先计划再执行”模式证实了这一点。我们必须将这个过程形式化。
   * 实现路径: 引入**“计划即代码”（Plan-as-Code）的概念。规划器Agent的输出不应是自然语言提示，而是一种可执行、可度量、可回放的计划DSL**。每个计划节点都应包含前置条件、接口契约、预算和验证器。
Part 2: 接下来的产品趋势是什么？
1. 从“AI副驾”到“AI自治团队” 我们正在从Copilot（辅助）模式，快速走向Jules/Oppie（任务完成）模式。下一步，将是多个自治AI Agent组成一个虚拟团队，协同完成更复杂的项目。想象一下：一个“AI产品经理”负责分析用户反馈并撰写PRD，一个“AI架构师”（即Oppie）负责设计和实现，一个“AI-QA”负责编写端到端测试，一个“AI-SRE”负责监控生产环境并自动修复问题。
2. 超级专业化的小模型（Hyper-Specialization） 未来的AI开发系统不会依赖一个巨大的通用模型，而是一个由成百上千个微型、廉价、高效的专家模型组成的网络。例如，一个专门用于“为React组件生成Vitest单元测试”的模型，一个专门“重构Go代码以减少内存分配”的模型。Oppie的Agent Orchestrator将负责调用这些专家。
3. 实时交互与架构共创 未来的交互将超越“你写需求，我给代码”。开发者会和AI进行架构层面的对话。“Oppie，对比一下我们这个新服务使用gRPC和REST的优劣，并为我生成两种方案的原型和性能测试报告。” AI将成为架构师的“结对编程”伙伴。
4. 自我修复与持续优化 AI工程师的工作将延伸到生产环境。它会监控应用性能、错误日志。一旦发现异常（例如，某个API的延迟上升），它会自动在沙箱中复现问题、探索解决方案、通过测试，并提交一个附带完整分析报告的Pull Request，等待人类批准。
Part 3: Libra AI的亮点与对Oppie的借鉴意义
你问Libra AI是不是只是标准解法。我的看法是：它的架构选择是标准的，但它的产品哲学和集成深度是顶级的亮点。
Libra AI的亮点：
生态原生（Ecosystem-Native）的极致集成：这是Libra最大的亮点。它不是一个“试图兼容所有环境”的通用工具，而是深度绑定Cloudflare生态的“原生应用”。它把Cloudflare的Workers, D1, R2, Queues等产品组合成一个天生就具备高性能、高可用性的PaaS平台。这种“All-in”某个生态的做法，牺牲了通用性，但换来了极致的开发和部署体验。
解决了“最后一公里”问题：Oppie的PRD聚焦于如何“智能地生成代码”，这是核心。但Libra提醒我们，代码生成后，认证、数据库、部署、域名、CDN等一系列“琐碎但致命”的工程问题才是价值交付的最后一公里。Libra把这些都打包解决了。
平台即沙箱（Platform-as-a-Sandbox）：Oppie用GitHub Actions做沙箱，而Libra的架构本身就是一个更高阶的沙箱。在Cloudflare上为每个用户项目动态创建一个Worker实例，这本身就是一种生产级别的高保真隔离环境。这对于MCTS的“验证”环节极具启发。
对Oppie的借鉴意义：
思考Oppie的“部署目标”：Oppie不应只是一个存在于开发者本地的“思考者”。它需要一个能与之高效联动的“身体”——即部署平台。Oppie可以考虑为特定生态（如Cloudflare, Vercel, Fly.io）提供深度优化。当Oppie为Cloudflare项目工作时，它不仅能生成JS代码，还能自动生成最优的wrangler.toml配置，并直接调用Wrangler API进行预览部署。
融合“编排器”与“平台”：Oppie的定位是“开发编排器”，Libra的定位是“AI原生开发平台”。终极形态的产品，很可能是一个内嵌了Oppie这种智能大脑的Libra平台。用户在一个地方完成从想法到全球部署的全过程，而无需关心底层是MCTS在搜索，还是Queues在部署。
将基础设施作为奖励函数的一部分：Libra的实践表明，应用性能与基础设施配置密切相关。Oppie的奖励函数可以加入基础设施成本和性能指标。例如，某个代码方案虽然优雅，但会导致更高的数据库连接数，那么它的“奖励”就应该被调低。
Part 4: 我们应该问什么样的问题？（核心假设升级）
我们必须对我们最核心的几个假设进行升级：
| 原假设 (Original Assumption) | 升级后假设 (Upgraded Assumption) |
|---|---|
| “CI沙箱足够用于主循环” | “主循环必须在热态、秒级的微虚机中，CI只用于最终验证” |
| “一个全能大模型是核心” | “一个由多个专家小模型构成的、由强编排器调度的网络是核心” |
| “奖励函数主要关注代码质量” | “奖励函数是代码质量、基础设施成本和业务风险的加权组合” |
| “计划是自然语言提示” | “计划是头等公民，是一种可执行、可度量的DSL (Plan-as-Code)” |
| “目标是生成一个通过测试的PR” | “目标是生成一个在‘人类审查时间↓’和‘线上SLO不退化’双重约束下最优的PR” |
Part 5: [新增] 近期行动方案 (Next 3 Weeks Action Plan)
基于升级后的假设，我们必须立即采取以下“硬动作”，以验证技术路径并加速迭代：
 * 【循环速度】主循环沙箱迁移PoC:
   * 目标: 将核心的“测试-验证”循环从GitHub Actions迁移到一个热态沙箱。
   * 动作: 启动一个并行实验，分别用Firecracker和Devcontainer on a persistent VM实现一个标准的测试任务。
   * 产出: 对比两种方案的循环延迟（目标：秒级）、资源隔离性和状态管理复杂度，形成技术选型报告。
 * 【规划能力】定义Plan-as-Code DSL v0.1:
   * 目标: 将任务规划过程形式化。
   * 动作: 设计一个最小化的计划DSL（可用YAML或JSON表示），定义节点结构：{id, description, dependencies, tool_to_use, input_contract, validation_oracle, budget}。
   * 产出: 一个能被规划器Agent生成、并能被执行器Agent解析的计划语言规范。
 * 【奖励设计】升级奖励函数 v1.1:
   * 目标: 将基础设施指标和风险纳入评估。
   * 动作: 在奖励函数中增加三个可量化的新维度：① Infra-Cost: 模拟的冷启动时间、内存峰值；② Token-Cost: API调用成本；③ Risk-Score: 依赖树变更风险评分。
   * 产出: 一个能对PR进行更全面、更现实评估的新版奖励函数。
 * 【学习能力】构建轨迹仓 (Episode Store) v1:
   * 目标: 开始积累AlphaZero赖以学习的核心数据资产。
   * 动作: 为NineAgent的夜间任务建立一个简单的数据库，存储每次MCTS运行的完整轨迹（计划 -> 工具调用 -> 观察 -> 结果 -> 奖励）。
   * 产出: 一个可检索的“经验库”，为后续的价值网络微调和近邻复用做准备。
 * 【信任设计】启动Trust-UX v1:
   * 目标: 解决AI生成代码的“黑盒”问题，构建人机信任。
   * 动作: 设计一个PR模板，要求Oppie提交的每个PR都必须自动附带：① 决策树可视化链接；② 主要风险点提示（如“修改了核心认证逻辑”）；③ 一键复现环境的脚本。
   * 产出: 一个能显著降低人类工程师审查心智负担的PR交付标准。

